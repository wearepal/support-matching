# ===== dataset flags =====
b_dataset: "cmnist"
b_filter_labels: 2 4
b_padding: 2
b_context_pcnt: 0.66666666
# bias the context set
b_subsample_context:
        0: 0.7
        1: 0.5
        2: 0.3
b_subsample_train:
        1: 0.3
        2: 0.0  # remove this group entirely
b_scale: 0

# ===== clustering flags =====
c_encoder: "ae"
c_enc_levels: 4
c_enc_chan: 16
c_enc_epochs: 90
c_recon_loss: l2
c_kl_weight: 1
c_std_transform: exp
c_log_freq: 50
c_cl_hidden_dims:
c_epochs: 100
c_method: "pl_enc_no_norm"
c_val_freq: 10

# ===== disentangling flags =====
d_three_way: False
d_eval_on_recon: True
d_levels: 4
d_enc_chan: 16
d_recon_loss: l2
d_vae: False
d_pred_s_weight: 2
d_kl_weight: 1
d_std_transform: exp
# this makes zs channels be 1
d_zs_frac: 0.0469
d_num_disc_updates: 3
d_log_freq: 50
d_disc_hidden_dims: 256 256
d_warmup_steps: 1000
d_super_val_freq: 20
d_super_val: True
d_pred_weight: 1
# Myles says this works better:
#d_train_on_recon: False
d_train_on_recon: True
